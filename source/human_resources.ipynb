{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**THE POWER OF RANDOM FORESTS**\n",
    "\n",
    "This is my first notebook. I decided to pick what i think it's an easy dataset to start with.\n",
    "Don't expect anything professional as I am just a beginner and I still have a lot to learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### The dataset used in this notebook can be downloaded at \n",
    "\n",
    "https://www.kaggle.com/ludobenistant/hr-analytics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# This Python 2 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) \n",
    "# will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\")) # checking name and location of the dataset\n",
    "\n",
    "# I'm using python2 so I need true division between integers\n",
    "from __future__ import division\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# option to print pandas objects with fewer digits\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#import and check data\n",
    "data = pd.read_csv('../input/HR_comma_sep.csv')\n",
    "data.head()\n",
    "                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "First of all we check number of features of the dataset and check how many categorical  and how many numeric features we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "print(data._get_numeric_data().shape[1], data.select_dtypes(include=['object']).shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#We only have 2 categorical features 'sales' and 'salary' so let's check them out\n",
    "print(data.salary.unique(), data.sales.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We now do a little bit of basic analysis on the categorical features to see if we find any interesting relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#group by salary we check how many left per group and then compare wuth total number per group\n",
    "salary_left = data.groupby(['salary']).agg({'left': np.sum}) \n",
    "salary_count = data.salary.value_counts()\n",
    "# concat the two columns\n",
    "salary_tot = pd.concat([salary_count, salary_left], axis=1)\n",
    "# add ratio per group of people left over total number\n",
    "salary_tot['ratio'] = salary_tot.apply(lambda x: x['left'] / x['salary'], axis=1)\n",
    "salary_tot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "As regards as the salary we can see that the lower the salary the more probable is people to leave.\n",
    "\n",
    "For low wages the percentage is almost 30%, while the mean is about 18%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#the same with sales\n",
    "sales_left = data.groupby(['sales']).agg({'left': np.sum})\n",
    "sales_count = data.sales.value_counts()\n",
    "# concat the two columns\n",
    "sales_tot = pd.concat([sales_count, sales_left], axis=1)\n",
    "# add ratio per group of people left over total number\n",
    "sales_tot['ratio'] = sales_tot.apply(lambda x: x['left'] / x['sales'], axis=1)\n",
    "sales_tot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In this case the ratio are very similar apart from management and RandD. This means that the department does not have much influence about the decision to leave. The mean is about 0.23."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "After exploring this features we now use pandas get_dummies to convert those string to columns with numeric values. First we check if there are any missing values tough.\n",
    "This is the first, and probably easier, approach we try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#check if there is any nan values. A similar result could be achieved using data.info \n",
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "It seems like we have no NaN values: good!! We can now convert strings. \n",
    "As first approach we try to use the get_dummies function provided by pandas.\n",
    "This function builds a boolean column for each unique value of a non-numerical column.\n",
    "So for example the salary column will be transformed in 3 different boolean column, one for each of its values:\n",
    " - salary_high\n",
    " - salary_medium\n",
    " - salary_low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dummies_data = pd.get_dummies(data)\n",
    "dummies_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Ok we added some features (3 for salary and 8 for sales) we can calculate the correlation between those features and the left column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# compute correlation matrix to check if there are any linear relation between features\n",
    "corr_mat = dummies_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# We are actually interested in correlation between the target feature and the others\n",
    "# select only best values and use seaborn to plot heatmap\n",
    "target_corr = corr_mat['left'].abs() #even large negative correlations are meaningful\n",
    "#we take the best 5 plus the obvious left column. This choice is due to the fact\n",
    "#that all other features have very low correlation wrt target feature 'left' (< 0.02)\n",
    "target_corr = target_corr.nlargest(6) \n",
    "cols = target_corr.index.tolist() # columns to use to plot correlation matrix\n",
    "new_corr_mat = dummies_data[cols].corr()\n",
    "plt.figure(figsize=[12,12]) #we only plot correlation between what we think are the best features\n",
    "sns.heatmap(new_corr_mat, annot=True, fmt=\".2f\", cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "As we might expect satisfaction_level is one of the main reason to leave. This is reflected by the fact that left and satisfaction are negatively correlated: the higher the satisfaction the more likely people are to stay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#filter data keeping only features with highest correlation\n",
    "filtered_data = dummies_data[cols]\n",
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#a general function to evaluate our models\n",
    "\n",
    "def evaluate(model, df, target_col, iterations=10, test_size=0.3):\n",
    "    tot_score = 0.\n",
    "    tot_rmse = 0.\n",
    "    for i in range(iterations):\n",
    "        train, test = train_test_split(df, test_size=test_size)\n",
    "    \n",
    "        X_train = train.drop([target_col], axis=1)\n",
    "        y_train = train[target_col]\n",
    "        X_test = test.drop([target_col], axis=1)\n",
    "        y_test = test[target_col]    \n",
    "    \n",
    "        # Train the model using the training sets\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Coefficients: this is the m term in the formula f(x) = mx + q\n",
    "        #print('Coefficients: \\n', regr.coef_, regr.intercept_)\n",
    "        pred = model.predict(X_test)\n",
    "        #emp_pred_values = pd.Series(pred, index=X_test.index)\n",
    "        #print(pd.concat([emp_pred_values.head(),y_test.head()], axis=1))\n",
    "        # Mean squared error\n",
    "        rmse = mean_squared_error(y_test, pred)**0.5\n",
    "        print(\"Root mean squared error: %.2f\"% rmse)\n",
    "        # Explained variance score: 1 is perfect prediction\n",
    "        score = model.score(X_test, y_test)\n",
    "        print('Variance score: %.2f' % score)\n",
    "        tot_rmse += rmse\n",
    "        tot_score += score\n",
    "    \n",
    "    print('\\nAverage score: %.2f' % float(tot_score/iterations))\n",
    "    print('Average rmse: %.2f' % float(tot_rmse/iterations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "################## Helper functions #######################\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# another general function yielding data needed for the confusion matrix\n",
    "def predict(model, X_train, y_train, X_test) : #X_train, y_train to fit the model, X_test to evaluate it\n",
    "    #fit and make predictions\n",
    "    model.fit(X_train, y_train)\n",
    "    return model.predict(X_test)\n",
    "\n",
    "# a function to compute and plot the confusion matrix\n",
    "def plot_conf_matrix(actual_values, predicted_values) :\n",
    "    #compute confusion matrix\n",
    "    conf_mat = confusion_matrix(predicted_values, actual_values)\n",
    "    #name blocks\n",
    "    idx = ['remained','left']\n",
    "    #convert matrix to dataframe to plot\n",
    "    df_cm = pd.DataFrame(conf_mat, index = idx, columns = idx)\n",
    "    #plot confusion matrix\n",
    "    plt.figure(figsize = (10,7))\n",
    "    plt.xlabel('Actual values')\n",
    "    plt.ylabel('Predicted values')\n",
    "    sns.heatmap(df_cm, annot=True, fmt='d')\n",
    "    \n",
    "#prepare data for prediction\n",
    "def split_data(df, target_column, test_size) :\n",
    "    train, test = train_test_split(df, test_size=test_size)\n",
    "    X_train = train.drop([target_column], axis=1)\n",
    "    y_train = train[target_column]\n",
    "    X_test = test.drop([target_column], axis=1)\n",
    "    y_test = test[target_column]\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Linear regression without regularization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "logReg_model = LogisticRegression()\n",
    "evaluate(logReg_model, df=filtered_data, iterations=10, target_col='left', test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#we now plot a confusion matrix to check our model accuracy\n",
    "\n",
    "#prepare train and test sets\n",
    "X_train, y_train, X_test, y_test = split_data(filtered_data, 'left', 0.3)\n",
    "\n",
    "#fit and make predictions\n",
    "pred = predict(logReg_model, X_train, y_train, X_test)\n",
    "\n",
    "#compute and plot confusion matrix\n",
    "plot_conf_matrix(y_test, pred); #semicolon to avoid memory location printing of the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Lots of mistakes. Linear regression and maybe our representation of data is wrong!! Let's try different models and see how they perform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Decision trees**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "tree_model = tree.DecisionTreeClassifier()\n",
    "evaluate(tree_model, df=filtered_data, iterations=10, target_col='left', test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#we now plot a confusion matrix to check our model accuracy\n",
    "\n",
    "#prepare train and test sets\n",
    "X_train, y_train, X_test, y_test = split_data(filtered_data, 'left', 0.3)\n",
    "\n",
    "#fit and make predictions\n",
    "pred = predict(tree_model, X_train, y_train, X_test)\n",
    "\n",
    "#compute and plot confusion matrix\n",
    "plot_conf_matrix(y_test, pred); #semicolon to avoid memory location printing of the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Much better than basic linear regression: 220 mistakes over nearly 4500 samples. Not perfect tough!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Random Forests**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model = RandomForestClassifier()\n",
    "evaluate(rf_model, df=filtered_data, iterations=10, target_col='left', test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#we now plot a confusion matrix to check our model accuracy\n",
    "\n",
    "#prepare train and test sets\n",
    "X_train, y_train, X_test, y_test = split_data(filtered_data, 'left', 0.3)\n",
    "\n",
    "#fit and make predictions\n",
    "pred = predict(rf_model, X_train, y_train, X_test)\n",
    "\n",
    "#compute and plot confusion matrix\n",
    "plot_conf_matrix(y_test, pred); #semicolon to avoid memory location printing of the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "A little bit better than decision tree with 200 misclassifications. \n",
    "Random forests seem to be the best choice for our dataset so with the next manipulation of data we are going to use this model only. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**A different approach to choose features and data representation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "First we try random forests just dropping the categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "numeric_features = data.drop(['sales','salary'], axis=1)\n",
    "evaluate(df=numeric_features,iterations=5,model=rf_model,target_col='left',test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#we now plot a confusion matrix to check our model accuracy\n",
    "\n",
    "#prepare train and test sets\n",
    "X_train, y_train, X_test, y_test = split_data(numeric_features, 'left', 0.3)\n",
    "\n",
    "#fit and make predictions\n",
    "pred = predict(rf_model, X_train, y_train, X_test)\n",
    "\n",
    "#compute and plot confusion matrix\n",
    "plot_conf_matrix(y_test, pred); #semicolon to avoid memory location printing of the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "As we can see by dropping 'sales' and 'salary' we improved our accuracy. This means that our first approach was not the best one. We now try another approach using LabelEncoder to check if we can  improve further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "encoded = data\n",
    "encoded.sales = le.fit_transform(encoded.sales)\n",
    "encoded.salary = le.fit_transform(encoded.salary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "evaluate(df=encoded,iterations=5,model=rf_model,target_col='left',test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#we now plot a confusion matrix to check our model accuracy\n",
    "\n",
    "#prepare train and test sets\n",
    "X_train, y_train, X_test, y_test = split_data(encoded, 'left', 0.3)\n",
    "\n",
    "#fit and make predictions\n",
    "pred = predict(rf_model, X_train, y_train, X_test)\n",
    "\n",
    "#compute and plot confusion matrix\n",
    "plot_conf_matrix(y_test, pred); #semicolon to avoid memory location printing of the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Not much difference, but we are sure about one thing.\n",
    "In this case LabelEncoder is better than transform data using get_dummies (label better than binaries)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Another very interesting feature I found is the GridSearchCv used together with Pipeline.\n",
    "Those 2 functions allow us to choose the best parameters and use them automatically in the model created.\n",
    "Let's give it a try using our label encoded model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "First a simple example on how to use a pipeline.\n",
    "\n",
    "Suppose we want to use the Random_forest model with a different number of features to find the best for our problem.\n",
    "In order to choose the best features we can use the SelectKBest function from the feature_selection module.\n",
    "The output of that process will go straight into our model using the pipeline into a coherent workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# we select the number of features to keep, in this case I choose at random 8\n",
    "best_feats = SelectKBest(k=8)\n",
    "\n",
    "# pipeline steps\n",
    "steps = [('feature_selection', best_feats),\n",
    "        ('random_forest', rf_model)]\n",
    "\n",
    "# create pipeline\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "#prepare train and test sets\n",
    "X_train, y_train, X_test, y_test = split_data(encoded, 'left', 0.3)\n",
    "\n",
    "#fit and make predictions\n",
    "pred = predict(rf_model, X_train, y_train, X_test)\n",
    "\n",
    "# test accuracy with metrics.classification_report this gives more info wrt to the confusion matrix\n",
    "print(classification_report(y_test, pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We are now ready to use GridSearchCV. This will allow us to use different parameters for the pipeline.\n",
    "In our case we'll try different values of KBest features and different parameters for the rf_model\n",
    "(For this example I'll change n_estimators and min_sample_split but we can choose any other parameter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# create parameters to evaluate with the GridSearchCV we use a dict here, but it's not the only possible choice\n",
    "# gridSearch will try any possible combination and choose the best for us, so this could be a bit slow so be patient\n",
    "\n",
    "parameters = dict(feature_selection__k=[6,8,9], #how many features to consider each iteration\n",
    "                  random_forest__n_estimators=[15,20,25], #change number of estimators\n",
    "                  random_forest__min_samples_split=[2,4] #vary number of sample splits\n",
    "                 )\n",
    "\n",
    "# prepare cross validation for Grid Search\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters)\n",
    "\n",
    "# prepare train and test sets\n",
    "X_train, y_train, X_test, y_test = split_data(encoded, 'left', 0.3)\n",
    "\n",
    "\n",
    "# make prediction on X_test\n",
    "pred = predict(cv, X_train, y_train, X_test)\n",
    "\n",
    "#print best parameters\n",
    "print(cv.best_params_)\n",
    "\n",
    "#print report \n",
    "report = classification_report(y_test, pred)\n",
    "print(report)\n",
    "\n",
    "plot_conf_matrix(y_test, pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Mind that in the report the number of positives and negatives it's not divided in True Positive, True Negatives and so on, that's why we plot the confusion matrix. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
